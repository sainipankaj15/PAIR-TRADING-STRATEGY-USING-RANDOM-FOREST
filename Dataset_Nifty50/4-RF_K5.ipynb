{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660817469147,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"D7I4aAH26KTD","outputId":"93655ab4-e127-4269-d1e5-6edcbd5ef27d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/MyDrive/BTP/Stock-market-forecasting'\n","/content/drive/MyDrive/BTP/Stock-market-forecasting\n"]}],"source":["cd drive/MyDrive/BTP/Stock-market-forecasting"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660817469148,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"2AKKWboA8VrA"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660817469148,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"pvU5SeKN8VoS"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660817469148,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"8fAys5ws8VlO"},"outputs":[],"source":["# 4 RF"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":7,"status":"error","timestamp":1660817469149,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"z1aCW7nA8X-r","outputId":"eb59dc76-0e9e-406f-c223-123f76e3153e"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-18-54fa4809ea82\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mStatistics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import pickle\n","from sklearn.ensemble import RandomForestClassifier\n","from Statistics import Statistics\n","\n","import os\n","SEED = 9\n","os.environ['PYTHONHASHSEED']=str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","\n","\n","SP500_df = pd.read_csv('data/SPXconst.csv')\n","all_companies = list(set(SP500_df.values.flatten()))\n","# all_companies.remove(np.nan)\n","\n","constituents = {'-'.join(col.split('/')[::-1]):set(SP500_df[col].dropna()) \n","                for col in SP500_df.columns}\n","\n","\n","\n","\n","\n","constituents_train = {} \n","for test_year in range(2013,2020):\n","    months = [str(t)+'-0'+str(m) if m\u003c10 else str(t)+'-'+str(m) \n","              for t in range(test_year-3,test_year) for m in range(1,13)]\n","    constituents_train[test_year] = [list(constituents[m]) for m in months]\n","    constituents_train[test_year] = set([i for sublist in constituents_train[test_year] \n","                                         for i in sublist])\n","    \n","\n","\n","\n","\n","def trainer(train_data,test_data):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    \n","    train_x,train_y = train_data[:,2:-2],train_data[:,-1]\n","    train_y = train_y.astype('int')\n","\n","    print('Started training')\n","    clf = RandomForestClassifier(n_estimators=1000, \n","        max_depth=10, \n","        random_state = SEED, \n","        n_jobs=-1)\n","    clf.fit(train_x,train_y)\n","    print('Completed ',clf.score(train_x,train_y))\n","\n","    \n","    \n","\n","    dates = list(set(test_data[:,0]))\n","    predictions = {}\n","    for day in dates:\n","        test_d = test_data[test_data[:,0]==day]\n","        test_d = test_d[:,2:-2] \n","        predictions[day] = clf.predict_proba(test_d)[:,1]\n","\n","    predicted_values = clf.predict(X_test)\n","\n","    accuracy = metrics.accuracy_score(Y_test, predicted_values)  \n","    \n","    return predictions\n","\n","\n","def simulate(test_data,predictions,test_year):\n","    rets = pd.DataFrame([],columns=['Long','Short'])\n","    k = 5\n","    fil = np.array(pd.read_csv('data/SPXconst.csv', header=None))\n","    for day in sorted(predictions.keys()):\n","        preds = predictions[day]\n","        test_returns = test_data[test_data[:,0]==day][:,-2]\n","        top_preds = predictions[day].argsort()[-k:][::-1] \n","        trans_long = test_returns[top_preds]\n","        worst_preds = predictions[day].argsort()[:k][::-1] \n","\n","\n","        #for 10 stocks\n","        # doc = pd.DataFrame([],columns=['date','1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n","        # doc.loc[day] = [day, fil[top_preds[0]+1][0], fil[top_preds[1]+1][0], fil[top_preds[2]+1][0], fil[top_preds[3]+1][0], fil[top_preds[4]+1][0], fil[top_preds[5]+1][0], fil[top_preds[6]+1][0],fil[top_preds[7]+1][0], fil[top_preds[8]+1][0], fil[top_preds[9]+1][0] ]\n","        # doc.to_csv(result_folder+'/longbuy-'+str(test_year)+'.csv', mode='a', index=False, header=False)\n","\n","        # doc1 = pd.DataFrame([],columns=['date','1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n","        # doc1.loc[day] = [day, fil[worst_preds[0]+1][0], fil[worst_preds[1]+1][0], fil[worst_preds[2]+1][0], fil[worst_preds[3]+1][0], fil[top_preds[4]+1][0], fil[worst_preds[5]+1][0], fil[worst_preds[6]+1][0],fil[worst_preds[7]+1][0], fil[worst_preds[8]+1][0], fil[worst_preds[9]+1][0] ]\n","        # doc1.to_csv(result_folder+'/shortsell-'+str(test_year)+'.csv', mode='a', index=False, header=False)\n","\n","\n","        #for 5 stock\n","        doc = pd.DataFrame([],columns=['date','1', '2', '3', '4', '5'])\n","        doc.loc[day] = [day, fil[top_preds[0]+1][0], fil[top_preds[1]+1][0], fil[top_preds[2]+1][0], fil[top_preds[3]+1][0], fil[top_preds[4]+1][0] ]\n","        doc.to_csv(result_folder+'/longbuy-'+str(test_year)+'.csv', mode='a', index=False, header=False)\n","\n","        doc1 = pd.DataFrame([],columns=['date','1', '2', '3', '4', '5'])\n","        doc1.loc[day] = [day, fil[worst_preds[0]+1][0], fil[worst_preds[1]+1][0], fil[worst_preds[2]+1][0], fil[worst_preds[3]+1][0], fil[top_preds[4]+1][0] ]\n","        doc1.to_csv(result_folder+'/shortsell-'+str(test_year)+'.csv', mode='a', index=False, header=False)\n","\n","        trans_short = -test_returns[worst_preds]\n","        rets.loc[day] = [np.mean(trans_long),np.mean(trans_short)] \n","    return rets   \n","    \n","def create_label(df_open,df_close,perc=[0.5,0.5]):\n","    if not np.all(df_close.iloc[:,0]==df_open.iloc[:,0]):\n","        print('Date Index issue')\n","        return\n","    perc = [0.]+list(np.cumsum(perc))\n","    label = (df_close.iloc[:,1:]/df_open.iloc[:,1:]-1).apply(\n","            lambda x: pd.qcut(x.rank(method='first'),perc,labels=False), axis=1)\n","    return label\n","\n","def create_stock_data(df_close,df_open,st):\n","    st_data = pd.DataFrame([])\n","    st_data['Date'] = list(df_close['Date'])\n","    st_data['Name'] = [st]*len(st_data)\n","    \n","    daily_change = df_close[st]/df_open[st]-1\n","    m = list(range(1,20))+list(range(20,241,20))\n","    for k in m:\n","        st_data['IntraR'+str(k)] = daily_change.shift(k)\n","    for k in m:\n","        st_data['CloseR'+str(k)] = df_close[st].pct_change(k).shift(1)\n","        #newline added\n","    for k in m:\n","        st_data['OpenR'+str(k)] = df_open[st].pct_change(k).shift(1)\n","        #endline added\n","    for k in m:\n","        st_data['OverNR'+str(k)] = df_open[st]/df_close[st].shift(k)-1\n","        \n","    st_data['R-future'] = daily_change \n","    st_data['label'] = list(label[st]) \n","    st_data['Month'] = list(df_close['Date'].str[:-3])\n","    st_data = st_data.dropna()\n","    \n","    trade_year = st_data['Month'].str[:4]\n","    st_data = st_data.drop(columns=['Month'])\n","    st_train_data = st_data[trade_year\u003cstr(test_year)]\n","    st_test_data = st_data[trade_year==str(test_year)]\n","    return np.array(st_train_data),np.array(st_test_data) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1660817469149,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"PwZACSnY8dYA"},"outputs":[],"source":["result_folder = 'results-Intraday-240-4-RF-pankaj-new-stock-50t'\n","for directory in [result_folder]:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1660817469150,"user":{"displayName":"PANKAJ KUMAR SAINI","userId":"16231200993537912085"},"user_tz":-330},"id":"L2y5zrLw8hkz"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------\n","2013\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23688, 128) (11656, 128) 5.942997932434082\n","Started training\n","Completed  0.7917510976021614\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.008041819307572792\n","Standard dev \t 0.01357235306697733\n","Sharpe ratio \t 9.054993698715025\n","----------------------------------------\n","2014\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23547, 128) (11421, 128) 5.775244474411011\n","Started training\n","Completed  0.7795048201469401\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.00806452477206845\n","Standard dev \t 0.01364258024856577\n","Sharpe ratio \t 9.034801872315873\n","----------------------------------------\n","2015\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23359, 128) (11609, 128) 5.707096815109253\n","Started training\n","Completed  0.7838520484609787\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.005611378046177217\n","Standard dev \t 0.011831250757414239\n","Sharpe ratio \t 7.126508794732518\n","----------------------------------------\n","2016\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23359, 128) (11562, 128) 5.727999687194824\n","Started training\n","Completed  0.8100518001626782\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.004485801904527236\n","Standard dev \t 0.01206178140862392\n","Sharpe ratio \t 5.508932968479182\n","----------------------------------------\n","2017\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23265, 128) (11656, 128) 5.690229415893555\n","Started training\n","Completed  0.8135826348592307\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.004090819514838318\n","Standard dev \t 0.010122501061442407\n","Sharpe ratio \t 5.944913598238863\n","----------------------------------------\n","2018\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23500, 128) (11562, 128) 5.824958324432373\n","Started training\n","Completed  0.8026808510638298\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.003517805746139194\n","Standard dev \t 0.011496033474687853\n","Sharpe ratio \t 4.4433658567596215\n","----------------------------------------\n","2019\n","----------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"]},{"name":"stdout","output_type":"stream","text":["Created : (23453, 128) (11515, 128) 5.449565410614014\n","Started training\n","Completed  0.8314501343111755\n","\n","Average returns prior to transaction charges\n","Mean \t\t 0.0020613776072041265\n","Standard dev \t 0.010982774965287384\n","Sharpe ratio \t 2.5458959843587334\n"]}],"source":["for test_year in range(2013,2020):\n","    \n","    print('-'*40)\n","    print(test_year)\n","    print('-'*40)\n","    \n","    filename = 'data/Open-'+str(test_year-3)+'.csv'\n","    df_open = pd.read_csv(filename)\n","    filename = 'data/Close-'+str(test_year-3)+'.csv'\n","    df_close = pd.read_csv(filename)\n","    \n","    label = create_label(df_open,df_close)\n","    stock_names = sorted(list(constituents[str(test_year-1)+'-12']))\n","    train_data,test_data = [],[]\n","    \n","    start = time.time()\n","    for st in stock_names:\n","        st_train_data,st_test_data = create_stock_data(df_close,df_open,st)\n","        train_data.append(st_train_data)\n","        test_data.append(st_test_data)\n","\n","    train_data = np.concatenate([x for x in train_data])\n","    test_data = np.concatenate([x for x in test_data])\n","    \n","    print('Created :',train_data.shape,test_data.shape,time.time()-start)\n","    \n","    predictions = trainer(train_data,test_data)\n","    returns = simulate(test_data,predictions,test_year)\n","    result = Statistics(returns.sum(axis=1))\n","    print('\\nAverage returns prior to transaction charges')\n","    result.shortreport() \n","    \n","    with open(result_folder+'/predictions-'+str(test_year)+'.pickle', 'wb') as handle:\n","        pickle.dump(predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    \n","    returns.to_csv(result_folder+'/avg_daily_rets-'+str(test_year)+'.csv')\n","    with open(result_folder+\"/avg_returns.txt\", \"a\") as myfile:\n","        res = '-'*30 + '\\n' \n","        res += str(test_year) + '\\n'\n","        res += 'Mean = ' + str(result.mean()) + '\\n'\n","        res += 'Sharpe = '+str(result.sharpe()) + '\\n'\n","        res += '-'*30 + '\\n'\n","        myfile.write(res)\n","        "]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMuARZ09zPgZ/nzZv/cKsl6","collapsed_sections":[],"mount_file_id":"1CSvI6xnhKwMfkv5cjwODwZ4cIhOsRrBq","name":"4-RF.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}